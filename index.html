<!DOCTYPE html>
<html lang="en">
<head>
    <meta name="robots" content="index, follow">
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
    <meta name="description" content="Personal website of Mohammad Soltanshah, Instructor and Ph.D. candidate at Simon Fraser University specializing in machine learning and robotics.">
    <meta name="keywords" content="Mohammad Soltanshah, Ph.D. candidate, robotics, machine learning, visual servoing, Simon Fraser University">

    <title>Mohammad Soltanshah</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 0;
            padding: 0;
            background-color: #f5f5f5;
            color: #333;
            font-size: 16px;
            line-height: 1.6;
        }

        header {
            background-color: #4CAF50;
            color: white;
            padding: 20px;
            text-align: center;
        }

        header h1 {
            margin: 0;
            font-size: 24px;
        }

        section {
            max-width: 100%;
            margin: 20px auto;
            padding: 0 5%;
            text-align: left;
        }

        .about-me {
            display: flex;
            flex-direction: column;
            align-items: center;
            font-size: 18px;
            text-align: center;
        }

        img.profile {
            width: 150px;
            height: 150px;
            object-fit: cover;
            border-radius: 50%;
            border: 2px solid #4CAF50;
        }

        footer {
            margin-top: 20px;
            padding: 10px 0;
            background-color: #4CAF50;
            color: white;
            text-align: center;
            font-size: 14px;
        }

        footer a {
            color: white;
            text-decoration: none;
        }

        footer a:hover {
            text-decoration: underline;
        }

        nav ul {
            list-style-type: none;
            padding: 0;
            display: flex;
            justify-content: center;
            flex-wrap: wrap;
            gap: 15px;
        }

        nav ul li {
            margin: 0 10px;
        }

        a {
            color: #4CAF50;
            text-decoration: none;
        }

        a:hover {
            text-decoration: underline;
        }

        /* Responsive Design */
        @media (min-width: 768px) {
            .about-me {
                flex-direction: row;
                text-align: left;
            }

            img.profile {
                width: 200px;
                height: 200px;
            }

            section {
                width: 70%;
                padding: 0 20px;
            }

            header h1 {
                font-size: 32px;
            }
        }

        /* Adjust image sizes for smaller screens */
        img {
            max-width: 100%;
            height: auto;
            border-radius: 5px;
        }

        ul {
            padding-left: 20px;
        }

        /* Fix touch issues in iOS */
        * {
            -webkit-tap-highlight-color: rgba(0,0,0,0);
            touch-action: manipulation;
        }

        #about-me a {
            color: #000; /* Set the link color to black */
        }

        #about-me .about-me p {
            line-height: 1.6; /* Adjust the value as needed */
        }


    </style>
</head>
<body>
    <header>
        <h1>Mohammad Soltanshah</h1>
        <p>Researcher | Software Developer | Instructor</p>
        <nav>
            <ul>
                <li><a href="#about-me">About Me</a></li>
                <li><a href="#publications">Publications</a></li>
                <li><a href="#teaching">Teaching</a></li>
            </ul>
        </nav>
    </header>

    <section id="about-me">
        <div class="about-me">
            <img src="projects/mohammad_soltanshah_photo.jpg" alt="Mohammad Soltanshah" class="profile">
            <p>
                I am an <strong>instructor</strong> and <strong>Ph.D. candidate</strong> in Engineering Science at <strong>Simon Fraser University (SFU)</strong>. 
                My reserach focuses on the intersection of <strong>machine learning</strong> and <strong>visual servoing</strong> for robotic tasks,
                with an emphasis on <strong>Deep Reinforcement Learning</strong> and <strong>Image-space Path Planning</strong> for <strong>robotic navigation, grasping and manipulation</strong>. I am part of <a href="https://sites.google.com/view/ramp-sfu/home?authuser=0" target="_blank" rel="noopener noreferrer">
                <strong>Robotic Algorithms & Motion Planning Laboratory (RAMP Laboratory)</strong></a> at SFU. Previously, I completed my M.Sc. at  Isfahan University of Technology, where my 
                thesis focused on SLAM-based navigation strategies for ground mobile robots operating in dynamic and unstructured environements.
            </p>
        </div>
    </section>

    <section id="publications">
        <h3>Publications</h3>
        <ul>
            <li style="display: flex; align-items: flex-start; margin-bottom: 20px;">
                <img src="papers/paper11.png" alt="Paper 1 Image" style="width: 200px; height: 150px; margin-right: 15px; object-fit: cover; border: 1px solid #ccc; padding: 5px;">
                <div>
                    <strong>Toward Autonomous Aerial Object Retrieval Utilizing RL-based Eye-to-hand/Eye-in-hand Feature Matching 
                        and Controllable-space Image Planning for Partitioned Visual Servoing</strong><br>
                    <span style="font-size: smaller;"><strong>Mohammad Soltanshah</strong>, Abolfazl Eskandarpour, Kamal Gupta, and Mehran Mehrandezh</span><br>
                    <span style="font-size: smaller;"><i>Submitted to IEEE International Conference on Robotics and Automation (ICRA), 2025.</i></span>
                </div>
            </li>
    
            <li style="display: flex; align-items: flex-start; margin-bottom: 20px;">
                <img src="papers/paper2.png" alt="Paper 2 Image" style="width: 200px; height: 150px; margin-right: 15px; object-fit: cover; border: 1px solid #ccc; padding: 5px;">
                <div>
                    <strong>Robust Partitioned Visual Servoing for Aerial Manipulation Utilizing Controllable-space Planning and Adaptive Image Representation</strong><br>
                    <span style="font-size: smaller;"><strong>Mohammad Soltanshah</strong>, Abolfazl Eskandarpour, Mehran Mehrandezh, and Kamal Gupta</span><br>
                    <span style="font-size: smaller;"><i>IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), 2024.</i></span>
                </div>
            </li>
    
            <li style="display: flex; align-items: flex-start; margin-bottom: 20px;">
                <img src="papers/paper3.png" alt="Paper 3 Image" style="width: 200px; height: 150px; margin-right: 15px; object-fit: cover; border: 1px solid #ccc; padding: 5px;">
                <div>
                    <strong>Hybrid Dynamic Modelling Using Feedforward and Temporal Convolutional Networks and Robust Control Scheme for Aerial Manipulators</strong><br>
                    <span style="font-size: smaller;">Abolfazl Eskandarpour, <strong>Mohammad Soltanshah</strong>, Kamal Gupta, and Mehran Mehrandezh</span><br>
                    <span style="font-size: smaller;"><i>IEEE International Conference on Automation Science and Engineering (CASE), 2024.</i></span>
                </div>
            </li>
    
            <li style="display: flex; align-items: flex-start; margin-bottom: 20px;">
                <img src="papers/paper4.png" alt="Paper 4 Image" style="width: 200px; height: 150px; margin-right: 15px; object-fit: cover; border: 1px solid #ccc; padding: 5px;">
                <div>
                    <strong>A Constrained Robust Switching MPC Structure for tilt-rotor UAV Trajectory Tracking Problem</strong><br>
                    <span style="font-size: smaller;">Abolfazl Eskandarpour, Mehran Mehrandezh, Kamal Gupta, Alejandro Ramirez-Serrano, and <strong>Mohammad Soltanshah</strong></span><br>
                    <span style="font-size: smaller;"><i>Nonlinear Dynamics, 111(18), 17247-17275, 2023.</i></span>
                </div>
            </li>
        </ul>
    </section><br>

    <section id="projects">
        <h3>Some Personal Projects</h3>
        <ul>
            <li style="display: flex; align-items: center; margin-bottom: 20px;">
                <img src="projects/jacobian_estimation.png" alt="Jacobian Estimation" style="width: 250px; height: 250px; margin-right: 20px; object-fit: cover; border: 1px solid #ccc; padding: 5px;">
                <div>
                    <strong>Aerial Manipulation Configuration Estimation Using RGB Images and Keras API</strong><br><br>
                    Aerial manipulation (AM) systems often face challenges with uncertainty and errors in estimating their configuration,
                     specifically the pose of the UAV and its manipulator arm. This project aims to train an aerial robot to estimate its
                      pose autonomously using only RGB images. The setup involves the robot hovering near a highlighted cylindrical object,
                       utilizing an eye-to-hand camera for QR code tracking and an eye-in-hand camera for generating RGB data.
                    This repository provides tools and models for configuration estimation in aerial manipulation tasks using deep learning
                     techniques. The primary focus is regression-based neural networks, complemented by visualization and analysis utilities.<br><br>

                    <a href="https://github.com/msoltanshah/configuration_estimation_aerial_manipulation" target="_blank">[Github Page]</a>
                </div>
            </li>
            <li style="display: flex; align-items: center; margin-bottom: 20px;">
                <img src="projects/practical_setup_3.png" alt="VS and Grasping for Open Manipulator" style="width: 250px; height: 250px; margin-right: 20px; object-fit: cover; border: 1px solid #ccc; padding: 5px;">
                <div>
                    <strong>Moving-object Visual Servoing and Grasping using Open Manipulator</strong><br><br>
                    VSGraspingNode is a ROS-based implementation for performing vision-based grasping operations for a moving object.
                     This node is responsible for receiving object pose information, handling start commands for visual servoing (VS),
                      and executing grasping actions. It also includes utility functions for matrix operations and coordinate transformations.
                       The setup uses Open Manipulator and Kinect.<br><br>
                    <a href="https://github.com/msoltanshah/visual_servoing_and_grasping_open_manipulator" target="_blank">[Github Page]</a>    
                </div>
                
            </li>
            <li style="display: flex; align-items: center; margin-bottom: 20px;">
                <img src="projects/rotary_tilting_wing_robot.png" alt="Rotary-tilting-wing Robot Modeling" style="width: 250px; height: 250px; margin-right: 20px; object-fit: cover; border: 1px solid #ccc; padding: 5px;">
                <div>
                    <strong>Rotary-tilting-wing Robot Modeling and Execution</strong><br><br>
                    This repository provides the developed Simscape/Simulink models for a rotary-tilting-wing robot system.
                     These models are designed to simulate the dynamics and control of an advanced aerial system, offering a platform to 
                     test various control strategies and system behaviors. The models use Simulinkâ€™s simulation features and include customizable
                      components for various experimental setups.<br><br>
                    <a href="https://github.com/msoltanshah/rotary_tilting_wing_robot_modeling" target="_blank">[Github Page]</a>
                </div>
                
            </li>
            <li style="display: flex; align-items: center; margin-bottom: 20px;">
                <img src="projects/astar_visualization.png" alt="A* Pathplanning Visualization" style="width: 250px; height: 250px; margin-right: 20px; object-fit: cover; border: 1px solid #ccc; padding: 5px;">
                <div>
                    <strong>A* Pathplanning Implementation and Visualization</strong><br><br>
                    This repository demonstrates a visualization of the A* pathfinding algorithm in a 2D grid using C++ and the SFML 
                    graphics library. The program generates random obstacles, highlights the start and end points, and animates the 
                    pathfinding process.<br><br>
                    <a href="https://github.com/msoltanshah/astar_visualization" target="_blank">[Github Page]</a>
                </div>
                
            </li>
        </ul>
    </section>

    <section id="teaching">
        <h3>Teaching</h3>
        <ul>
            <li>
                <strong>Instructor</strong>, ENSC 204: Graphical Communication for Engineering, Simon Fraser University,
                 Fall 2024, <a href="https://www.sfu.ca/outlines.html?2024/fall/ensc/204/e100">[course outline]</a><br><br>
                 An overview of engineering graphical communication, Computer-Aided Design (CAD), and workshop practices.
                 The course aims to enhance students' proficiency in using graphics to convey engineering concepts and their skills in visualizing 
                 and developing 3D models. It introduces the application of CAD software for creating 3D solid models and familiarizes students with
                  the ASME Y14.5 GD&T Standard. Additionally, students explore various simulation analyses of mechanical/electrical components.<br><br>
                  
                <strong>Outline</strong><br><br>
                
                <ul>
                    <li>
                       Module 1: Fundamentals of Technical Graphics
                    </li><br>
                    <li>
                       Moduel 2: Communication and Design using CAD
                    </li><br>
                    <li>
                       Module 3: Manual Drawing Techniques
                    </li><br>
                    <li>
                       Module 4: Standards for GD&T
                    </li><br>
                    <li>
                       Module 5: Application of Graphical Communication
                    </li><br>
                </ul>
            </li>
        </ul>
    </section>

    <footer>
        <p>Contact: <a href="mailto:mohammad_soltanshah@sfu.ca">mohammad_soltanshah@sfu.ca</a></p>
        <p>Find me on:
            <a href="https://www.linkedin.com/in/mohammad-soltanshah-39a64277/" target="_blank">LinkedIn</a> |
            <a href="https://github.com/msoltanshah" target="_blank">GitHub</a> |
        </p>
        <p>All rights reserved.</p>
    </footer>
</body>
</html>